{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dogecoin Price Prediction",
   "id": "4c3a2e1110bf23fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import necessary libraries",
   "id": "5fc76d4d4a8572f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:35:40.608948Z",
     "start_time": "2024-12-30T22:35:39.134013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump, load"
   ],
   "id": "48b2e1311b4ee254",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "c4dce11c0bae3475"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:35:40.643030Z",
     "start_time": "2024-12-30T22:35:40.624538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data from the CSV file\n",
    "doge_data = pd.read_csv('../data/dogecoin_data.csv')\n",
    "\n",
    "# Ensure the 'Date' column is present and set it as the index\n",
    "doge_data.reset_index(inplace=True)\n",
    "\n",
    "# Feature engineering: create additional features\n",
    "doge_data['Date'] = pd.to_datetime(doge_data['Date'])\n",
    "doge_data['Day'] = doge_data['Date'].dt.day\n",
    "doge_data['Month'] = doge_data['Date'].dt.month\n",
    "doge_data['Year'] = doge_data['Date'].dt.year\n",
    "doge_data['DayOfWeek'] = doge_data['Date'].dt.dayofweek\n",
    "doge_data.set_index('Date', inplace=True)\n",
    "doge_data.drop(columns=['index'], inplace=True)\n",
    "doge_data.ffill(inplace=True)\n",
    "\n",
    "# Verify that columns are unique\n",
    "if doge_data.columns.duplicated().any():\n",
    "    raise ValueError(f\"Duplicate columns found: {doge_data.columns[doge_data.columns.duplicated()]}\")\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the data\n",
    "print(doge_data.head())"
   ],
   "id": "13b09eb1b994de57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Close      High       Low      Open    Volume  Day  Month  \\\n",
      "Date                                                                       \n",
      "2020-01-01  0.001812  0.001829  0.001802  0.001808  45619467    1      1   \n",
      "2020-01-02  0.001798  0.001889  0.001775  0.001813  58247425    2      1   \n",
      "2020-01-03  0.001922  0.001951  0.001782  0.001797  56113646    3      1   \n",
      "2020-01-04  0.002008  0.002231  0.001837  0.001921  84437147    4      1   \n",
      "2020-01-05  0.002168  0.002231  0.001897  0.002007  47158934    5      1   \n",
      "\n",
      "            Year  DayOfWeek  \n",
      "Date                         \n",
      "2020-01-01  2020          2  \n",
      "2020-01-02  2020          3  \n",
      "2020-01-03  2020          4  \n",
      "2020-01-04  2020          5  \n",
      "2020-01-05  2020          6  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Columns Transformer and Pipeline",
   "id": "ac34fd8f94245055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:35:40.713969Z",
     "start_time": "2024-12-30T22:35:40.708541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the columns transformer\n",
    "transformer = ColumnTransformer([\n",
    "    ('date', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='date')),\n",
    "    ('high', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='high')),\n",
    "    ('low', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='low')),\n",
    "    ('open', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='open')),\n",
    "    ('volume', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='volume')),\n",
    "    ('day', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='day')),\n",
    "    ('month', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='month')),\n",
    "    ('year', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='year')),\n",
    "    ('dayofweek', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), make_column_selector(pattern='dayofweek')),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(categories='auto', drop='first', handle_unknown='ignore'))\n",
    "    ]), make_column_selector(dtype_include='category'))\n",
    "], remainder='passthrough', verbose_feature_names_out=True, sparse_threshold=0)\n",
    "\n",
    "# Define the steps for the pipeline\n",
    "steps = [\n",
    "    ('transformer', transformer),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "]\n",
    "\n",
    "# Define the RandomForest pipeline\n",
    "rf_pipeline = Pipeline(steps=steps)"
   ],
   "id": "8e49ef20d0efff28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Data",
   "id": "7f5de80d5f9f3496"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:35:40.757099Z",
     "start_time": "2024-12-30T22:35:40.751754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = doge_data.drop(columns=['Close'], axis=1)\n",
    "y = doge_data['Close']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "c1352f84e309b4f3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter Tuning",
   "id": "85430a1e829ed4fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:35:40.935055Z",
     "start_time": "2024-12-30T22:35:40.932737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the seeds for reproducibility\n",
    "cl_seeds = (42, 123, 643, 1337, 543, 1, 99, 885, 23, 77)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'regressor__random_state': cl_seeds,\n",
    "    'regressor__n_estimators': [200, 300, 400],\n",
    "    'regressor__max_depth': [None, 2, 5, 10, 20, 50],\n",
    "    'regressor__max_features': ['sqrt'],\n",
    "    'regressor__bootstrap': [True],\n",
    "}\n",
    "\n",
    "model_list = [('rf', rf_pipeline)]\n",
    "model_params_grid = [rf_param_grid]"
   ],
   "id": "b829448ab55401b9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Best Model",
   "id": "cb9c5c63949c293d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:36:08.684841Z",
     "start_time": "2024-12-30T22:35:41.219294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best model from grid search\n",
    "best_models_gs = []\n",
    "for (model_name, model), hp in zip(model_list, model_params_grid):\n",
    "    grid = GridSearchCV(model, hp, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best params: {grid.best_params_}, Best score: {grid.best_score_}\")\n",
    "    best_models_gs.append((model_name, grid.best_estimator_, grid.best_score_, grid.best_params_))\n",
    "\n",
    "hof_model_gs = max(best_models_gs, key=lambda item:item[2])\n",
    "print(f\"HoF Model: {hof_model_gs}\")"
   ],
   "id": "fadf9f3f8089612b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: rf\n",
      "Best params: {'regressor__bootstrap': True, 'regressor__max_depth': 10, 'regressor__max_features': 'sqrt', 'regressor__n_estimators': 200, 'regressor__random_state': 77}, Best score: -5.554124705695861e-05\n",
      "HoF Model: ('rf', Pipeline(steps=[('transformer',\n",
      "                 ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
      "                                   transformers=[('date',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f9770922cf0>),\n",
      "                                                 ('high',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='medi...\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f9770920050>),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OneHotEncoder(drop='first',\n",
      "                                                                                 handle_unknown='ignore'))]),\n",
      "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f9770923b30>)])),\n",
      "                ('regressor',\n",
      "                 RandomForestRegressor(max_depth=10, max_features='sqrt',\n",
      "                                       n_estimators=200, random_state=77))]), np.float64(-5.554124705695861e-05), {'regressor__bootstrap': True, 'regressor__max_depth': 10, 'regressor__max_features': 'sqrt', 'regressor__n_estimators': 200, 'regressor__random_state': 77})\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "4f7165efd00171e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:36:10.145658Z",
     "start_time": "2024-12-30T22:36:10.098709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Best model prediction and scores\n",
    "hof_gs = hof_model_gs[1]\n",
    "y_pred_train = hof_gs.predict(X_train)\n",
    "y_pred_test = hof_gs.predict(X_test)\n",
    "print(f'Mean Squared Error on training set: {mean_squared_error(y_train, y_pred_train)}')\n",
    "print(f'Mean Squared Error on test set: {mean_squared_error(y_test, y_pred_test)}')"
   ],
   "id": "8815c20dfc8c9b34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on training set: 8.347484636243886e-06\n",
      "Mean Squared Error on test set: 2.9353643991832407e-05\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the Model",
   "id": "abcce3fca77214e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:36:10.209138Z",
     "start_time": "2024-12-30T22:36:10.150891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Re-fit the model on the entire dataset\n",
    "y = doge_data['Close']\n",
    "x = doge_data.drop('Close', axis = 1)\n",
    "columns = x.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(x)\n",
    "X = scaler.transform(x)\n",
    "features = pd.DataFrame(X, columns = columns)\n",
    "\n",
    "# Save the transformer and model\n",
    "dump(transformer, '../models/doge_transformer.joblib')\n",
    "dump(hof_gs, '../models/doge_model.joblib')"
   ],
   "id": "b6e961d2536b98f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/doge_model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "a1be3bfadb85c2b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T22:36:11.085395Z",
     "start_time": "2024-12-30T22:36:11.026054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load new data for prediction\n",
    "high = 0.06\n",
    "low = 0.04\n",
    "open = 0.05\n",
    "volume = 1000000\n",
    "day = 1\n",
    "month = 1\n",
    "year = 2023\n",
    "dayofweek = 0\n",
    "feat_cols = features.columns\n",
    "\n",
    "row = [high, low, open, volume, day, month, year, dayofweek]\n",
    "\n",
    "# Load the transformer and model\n",
    "transformer = load('../models/doge_transformer.joblib')\n",
    "model = load('../models/doge_model.joblib')\n",
    "\n",
    "# Check the feature columns\n",
    "print(feat_cols)\n",
    "\n",
    "# Transform the new data\n",
    "df = pd.DataFrame([row], columns = feat_cols)\n",
    "tr = transformer.fit(df)\n",
    "X = tr.transform(df)\n",
    "features = pd.DataFrame(X, columns = feat_cols)\n",
    "\n",
    "# Making a prediction\n",
    "try:\n",
    "    prediction = model.predict(features)\n",
    "    print(f'Predicted Close Price: {prediction[0]}')\n",
    "except Exception as e:\n",
    "    print(f'Error during prediction: {e}')"
   ],
   "id": "1b749cfcb09ff6f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['High', 'Low', 'Open', 'Volume', 'Day', 'Month', 'Year', 'DayOfWeek'], dtype='object')\n",
      "Predicted Close Price: 0.0567910090986183\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
